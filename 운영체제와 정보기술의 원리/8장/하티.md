# 08. 가상메모리

## 가상 메모리

- 메모리의 연장 공간으로 스왑 영역이 사용될 수 있다.
- 프로그램이 물리적 메모리를 고려할 필요 없이 자기 자신만이 메모리를 사용하는 것처럼 가정해 프로그램하는 것을 지원한다.

⇒ 이 때, 프로그램은 0번지부터 시작하는 자기 자신만의 **메모리 주소 공간**을 가정할 수 있다 ⇒ `**가상메모리**`

- 프로세스마다 각각 0번지부터의 주소 공간을 가지게 되며, 일부는 물리적 메모리에 적재되고, 일부는 스왑 영역에 존재하게 된다.
- 가상메모리 기법
    - 프로세스의 주소 공간을 메모리로 적재하는 단위에 따라 구분
    - 요구 페이징 방식, 요구 세그먼테이션 방식
        - 주로 요구 페이징 방식이 사용됨.
        - 요구 세그멘테이션 방식 사용 → 페이지드 세그먼테이션 기법을 사용하는 경우

## 요구 페이징

- 프로그램 실행 시 당장 사용될 페이지만을 올리는 방식
- 특정 페이지에 대해 CPU 요청이 들어오면 → 해당 페이지를 메모리에 적재
- 장점
    - 메모리 사용량 감소
    - 프로세스 전체를 메모리에 올리는 데 사용되는 입출력 오버헤드 줄어듬
    - 응답시간 단축
    - 시스템이 더 많은 프로세스 수용 가능
    - 프로그램이 물리적 메모리의 용량 제약을 벗어날 수 있게 됨
        - 물리적 메모리의 용량보다 큰 프로그램도 실행 가능하니까~
- 일부 페이지만 메모리에 올라오고, 나머지 페이지는 스왑 영역에 존재한다.
- 유효-무효 비트 (valid-invalid bit)
    - 어떤 페이지가 메모리에 존재하고 존재하지 않는지를 구별하기 위한 방법
    - 유효-무효 비트를 두어 각 페이지가 메모리에 존재하는지를 표시
    - 페이지 테이블의 각 항목별로 저장
    - 프로세스 실행 전 → 무효값
        
        메모리에 적재되면 → 유효값
        
        스왑 영역으로 쫓겨나면 → 무효값
        

### 요구 페이징의 페이지 부재 (page fault) 처리

- 페이지 부재
    - CPU가 참조하려는 페이지가 현재 메모리에 올라와 있지 않아 유효-무효 비트가 무효로 세팅되어 있는 경우
- CPU가 무효 페이지에 접근하면
    
    → MMU (주소 변환을 담당하는 하드웨어)가 **페이지 부재 트랩 (page fault trap)**을 발생시킴 
    
    → CPU의 제어권 커널모드로 전환 
    
    → 운영체제의 **페이지 부재 처리루틴 (page fault handler)**이 호출 
    
    → 페이지 부재 처리
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/d4809f18-a915-4e30-8b11-8f015eacff00/306377cf-728c-433e-9fcf-9bcf0c583ce1/Untitled.png)
    
- 페이지 부재 처리 과정
    
    페이지에 대한 접근이 적법한가 체크 
    
    → 사용되지 않는 주소 영역에 속했거나, 접근 권한 위반을 한 경우 해당 프로세스 종료 
    
    (e.g. 읽기전용인데 쓰기 접근 시도) 
    
    → 접근이 적법하다면,  물리적 메모리에서 **비어 있는 `프레임`을 할당**받고, 그 공간에 해당 페이지를 읽어온다.
    
    (만약 비어 있는 프레임이 없다면, 기존 메모리에 있는 페이지 중 하나를 스왑 아웃 시킨다: **페이지 교체**)
    
    → 디스크에서 메모리로 페이지를 적재할 때, 페이지 부재를 발생시킨 프로세스는 **CPU를 빼앗기고 봉쇄 상태**가 되고, 상태를 **PCB에 저장** 
    
    →  디스크 입출력이 완료되어 **인터럽트가 발생**하면 **유효-무효 비트는 유효**가 되고 
    
    → **프로세스는 준비 큐**로 이동 
    
    → **CPU 재할당**받으면 **PCB로부터 복원**, **명령 실행 재개**
    

### 요구 페이징의 성능

- 요구 페이징 기법의 성능에 가장 영향을 크게 미치는 요소: **페이지 부재의 발생 빈도**
    - 페이지 부재가 발생하면 → 요청된 페이지를 디스크로부터 메모리로 읽어오는 **막대한 오버헤드가 발생**
- 즉, **페이지 부재가 적게 발생할수록 요구 페이징의 성능이 향상**

## 페이지 교체 (page replacement)

- 메모리에 올라와 있는 페이지 중 하나를 디스크로 쫓아내 메모리에 빈 공간을 확보하는 작업
- 교체 알고리즘
    - 어떤 프레임에 있는 페이지를 쫓아낼 것인지 결정하는 알고리즘
    - 목표: 페이지 부재율 최소화
    - 가까운 미래에 참조될 가능성이 가장 적은 페이지를 선택해서 내쫓음
- 성능
    - 주어진 페이지 참조열에 대해 페이지 부재율을 계산함으로써 평가
    - 페이지 참조열: 참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것
        - 해당 페이지 번호가 메모리에 있다면 → 메모리에서 `적중(hit)` 되었다
            
            없다면 → 페이지 부재 발생
            

### 최적 페이지 교체

- 페이지 교체 시, 물리적 메모리에 존재하는 페이지 중 가장 먼 미래에 참조될 페이지를 쫓아낸다.
- 미래에 어떤 페이지가 어떤 순서로 참조될 것인지 알고 있다는 전제하에 운영된다.
- 실제 시스템에서 온라인으로 사용할 수 없어, **오프라인 알고리즘**이다.
- 어떤 경우에서도 가장 적은 페이지 부재율 보장 → **성능의 상한선을 제공**

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/d4809f18-a915-4e30-8b11-8f015eacff00/b1e308b4-b01f-43b7-8c42-acb008cecf35/Untitled.png)

### 선입선출 알고리즘

- 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 내쫓는다.
    - 향후 참조 가능성을 고려하지 않음
- 비효율적인 상황이 발생할 수 있다.
    - 가장 먼저 메모리에 들어온 페이지가 계속해서 많은 참조가 이루어지는 경우
- FIFO의 이상 현상 (FIFO anomaly)
    - FIFO 알고리즘에서 메모리를 증가시켰음에도 불구하고 페이지 부재가 오히려 증가하는 상황

### LRU 알고리즘 (Least Recently Used)

- 시간지역성 (temporal locality)
    - 메모리 페이지의 참조 성향 중 중요한 성질
    - 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질
- 가장 오래전에 참조가 이루어진 페이지를 내쫓는다.
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/d4809f18-a915-4e30-8b11-8f015eacff00/f2411fae-1aee-4418-97ab-e0e69e401985/Untitled.png)
    

### LFU 알고리즘 (Least Frequently Used)

- 페이지의 참조 횟수가 가장 적었던 페이지를 쫓아낸다.
    - 참조 횟수가 가장 적은 페이지가 여러 개면 하나를 임의로 선정해 쫓아낸다.
    - 여러 개 중 상대적으로 예전에 참조된 페이지를 쫓아내는 것이 효율적
- 참조 횟수 계산 방법
    - **Incache-LFU**
        - 페이지가 물리적 메모리에 올라온 후부터의 참조 횟수
    - **Perfect-LFU**
        - 메모리에 올라오고 내려간 여부에 상관없이 총 참조 횟수
        - 메모리에서 쫓겨난 페이지의 참조 기록도 모두 보관해야 하므로 오버헤드가 상대적으로 크다.
- LRU와 비교했을 때,
    - `장점` 오랜 시간 동안의 참조 기록을 반영하다.
    - `단점` 시간에 따른 페이지 참조 변화를 반영하지 못하고, 구현이 복잡하다.

### 클럭 알고리즘 ( == NUR, NRU 알고리즘, 2차 기회 알고리즘) (Not Used Recently)

- 페이지의 참조 시각 혹은 참조 횟수를 유지하고 비교하면서 생기는 오버헤드를, 하드웨어적인 지원을 통해 줄인 방식
- 오랫동안 참조되지 않은 페이지 중 하나를 쫓아낸다.
    - 가장 오래된 X, 오랫동안 O
        
        ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/d4809f18-a915-4e30-8b11-8f015eacff00/f22d12ee-e47e-4d0a-a73f-d95f7c6dc1d1/Untitled.png)
        
    - 페이지 프레임들의 참조비트를 순차적으로 조사 → 참조비트가 1이면 0으로 교체 후 지나가고, 0이면 교체한다.
    - 참조비트: 프레임마다 하나씩 존재, 페이지가 참조되면 1로 세팅
    - 시곗바늘이 한 바퀴 도는 동안 참조되지 않은 페이지를 교차하는 것!
- 빠르고 효율적으로 페이지 관리가 이루어진다. (하드웨어적 지원 덕분에)
- 대부분의 시스템에서 페이지 교체 알고리즘으로 채택한다.

## 페이지 프레임의 할당

- 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인지 결정해야 한다.
- 할당 알고리즘 (allocation algorithm)) 세 가지 - 균등할당, 비례할당, 우선순위 할당

### 균등할당 방식 (equal allocation)

- 모든 프로세스에게 페이지 프레임을 균일하게 할당

### 비례할당 방식 (proportional allocation)

- 프로세스 크기에 비례해 프레임을 할당

### 우선순위 할당 방식 (priority allocation)

- 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당
- 당장 CPU에서 실행될 / 실행되지 않을 프로세스를 구분, 전자 쪽에 더 많은 프레임을 할당

### 문제점

- 할당 알고리즘 만으로는 프로세스의 페이지 참조 특성을 제대로 반영하지 못할 수 있다.
    - e.g. 현재 수행 중인 프로세스의 수가 지나치게 많다면 프로세스당 할당되는 메모리 양이 과도하게 적어질 수 있다.
- 종합적인 상황을 고려하여 각 프로세스에 할당되는 프레임의 수를 결정할 필요가 있다.
    - 정상적인 프로세스 수행을 위해, 적어도 일정 수준 이상의 페이지 프레임을 각 프로세스에 할당해야 한다.
    - 반복문을 실행 중인 프로세스의 경우, 반복문을 구성하는 페이지를 한꺼번에 메모리에 올려두는 것이 유리하다.
    - 프로세스에게 최소한으로 필요한 메모리의 양은 시간에 따라 다를 수 있다.

## 전역교체와 지역교체

- 교체할 페이지를 선정할 때, 교체 대상이 될 프레임의 범위를 어떻게 할 것인가

### 전역교체 (global replacement)

- 모든 페이지 프레임이 교체 대상이 될 수 있는 방법
- 전체 메모리를 각 프로세스가 공유해서 사용하고, 교체 알고리즘에 근거해서 할당되는 메모리 양이 가변적으로 변한다.
- LRU, LFU, 클럭 등이 물리적 메모리 내에 있는 전체 페이지 프레임들을 대상으로 적용하는 경우

### 지역 교체 (local replacement)

- 현재 수행 중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정할 수 있는 방법
- 프로세스마다 페이지 프레임을 미리 할당해둔다.
- LRU, LFU 등의 알고리즘을 프로세스별로 독자적으로 운영하는 경우

## 스레싱 (thrashing)

- 최소한의 페이지 프레임을 할당받지 못할 경우,
    
    집중적으로 참조되는 페이지들의 집합을 한꺼번에 메모리에 올리지 못해 페이지 부재율이 급상승하여 CPU 이용률이 급격히 떨어지는 현상
    
- CPU 이용률이 낮다면 → 메모리에 올라온 프로세스의 수가 적어서 준비 큐가 비는 경우가 생겼다고 판단 
→ 메모리에 올라가는 프로세스의 수 (**다중 프로그래밍의 정도** (Multi-programming degree: `MPD`)) 증가 → MPD가 과도하게 높아지면 각 프로세스에게 할당되는 메모리의 양 감소 
→ 페이지 부재 빈번히 발생 → 스왑인, 스왑 아웃 지속적 발생 → CPU 이용률 급하 → …. **⇒ 스레싱 발생**
- MPD를 적절히 조절해 CPU 이용률을 높이면서 스레싱 발생을 방지하는 방법
    - 워킹셋 알고리즘, 페이지 부재 빈도 알고리즘

### 워킹셋 알고리즘 (working-set algorithm)

- 프로세스는 일정 시간 동안 특정 주소 영역을 집중적으로 참조하는 경향이 있다.
- `지역성 집합 (locality set)`: 집중적으로 참조되는 페이지들의 집합
- `워킹셋 알고리즘`: 지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 알고리즘
- `워킹셋`: 한꺼번에 메모리에 올라와 있어야 하는 페이지들의 집합
- 워킹셋인 페이지들이 모두 메모리에 올라갈 수 있는 경우에만 메모리를 할당해준다.
    - 그렇지 않은 경우에는, 프로세스에세 할당된 페이지 프레임들을 모두 반납시킨 후,
        
        프로세스의 주소 공간 전체를 스왑 아웃
        
    - 이를 통해 MPD를 조절하고, 스레싱을 방지

### 페이지 부재 빈도 알고리즘 (page-fault algorithm)

- `페이지 부재 빈도 알고리즘`: 프로세스의 페이지 부재율을 주기적으로 조사, 이 값에 근거하여 각 프로세스에 할당할 메모리 양을 동적으로 조절한다.
- 페이지 부재율이 미리 정해놓은 **상한값**을 넘으면 → 할당된 프레임 수가 부족하군, 프레임을 추가로 할당
    - 추가로 할당할 빈 프레임이 없다면 일부 프로세스를 스왑 아웃
- 페이지 부재율이 **하한값** 이하라면 → 필요 이상으로 프레임이 너무 많군, 프레임 수를 줄인다.