# 8장. 가상메모리

운영체제는 보통 모든 프로그램들에 공평하게 같은 크기의 메모리를 할당하기보다는 몇몇 프로그램들에게 집중적으로 메모리를 할당한 후, 시간이 흐르면 이들로부터 메모리를 회수해서 다른 프로그램들에게 다시 집중적으로 메모리를 할당하는 방식을 채택한다. 프로세스의 빠른 수행을 위해 프로그램마다 최소 확보해야하는 크기가 존재하기 때문..

운영체제는 프로그램이 물리적 메모리를 고려할 필요 없이 자기 자신만이 메모리를 사용하는 것처럼 가정해 프로그램하는 것을 지원한다. 이렇게 하면 프로그램은 0번지부터 시작하는 자기 자신만의 메모리 주소 공간을 가정할 수 있는데, 이러한 메모리 공간을 **가상메모리**라고 부른다. 이들 공간 중 일부는 물리적 메모리에 적재되고 일부는 디스크의 스왑 영역에 존재하게 된다. 

가상 메모리 기법은 크게 요구 페이징 방식과 페이지드 세그먼테이션을 사용한다. 

</br>

## 요구 페이징

요구 페이징이란 프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아니라 당장 사용될 페이지만을 올리는 방식을 말한다. 

요구페이징 기법에서는 당장 실행에 필요한 페이지만을 메모리에 적재하기 때문에 메모리 사용량이 감소하고, 프로세스 전체를 메모리에 올리는데 소요되는 입출력 오버헤드도 줄어든다. 페이지 중 일부만을 메모리에 적재하게 되므로 물리적 메모리의 용량보다 큰 프로그램도 실행할 수 있게 된다. 

가상메모리 기법에서는 프로세스가 실행되는 동안 일부 페이지만 메모리에 올라와 있고 나머지 페이지는 디스크의 스왑 영역에 존재한다. 특정 프로세스를 구성하는 페이지 중에서 어떤 페이지가 메모리에 존재하고 존재하지 않는지 구분하기 위해 요구 페이징에서는 유효-무효 비트를 두어 각 페이지가 메모리에 존재하는지 표시하게 된다. 이 비트는 각 프로세스를 구성하는 모든 페이지에 대해 존재해야 하므로 페이지 테이블의 각 항목별로 저장된다. 

</br>

### 요구 페이징의 페이지 부재 처리

CPU가 참조하려는 페이지가 현재 메모리에 올라와 있지 않아 유효-무효 비트가 무효로 세팅되어 있는 경우를 페이지 부재(page fault)가 일어났다고 말한다. 

CPU가 무효 페이지에 접근하면 주소 변환을 담당하는 하드웨어인 MMU가 페이지 부재 트랩을 발생시키게 된다. 그러면 CPU의 제어권이 커널모드로 전환되고, 운영체제 의 페이지 부재 처리루틴이 (page fault handler)이 호출된다. 

즉 부재 상태의 페이지를 메모리에 적재하기에 앞서 접근이 적법한지를 먼저 체크한다. 사용되지 않는 주소 영역에 속한 페이지에 접근하려 했거나 해당 페이지에 대한 접근 권한 위반(protection violation)을 했을 경우에는 해당 프로세스를 종료시킨다. 예) 읽기 전용에 쓰기 권한으로 접근 시도

해당 페이지에 대한 접근이 적법한 경우 물리적 메모리에 비어있는 프레임을 할당 받아 그 공간에 해당 페이지를 읽어온다. 비어있는 프레임이 없다면 기존에 메모리에 올라와 있는 페이지 중 하나를 디스크로 스왑 아웃 시킨다. 

요청된 페이지를 디스크로부터 메모리로 적재하기까지는 오랜 시간이 소요된다. 따라서 페이지 부재를 발생시킨 프로세스는 CPU를 빼앗기고 봉쇄상태가 된다. 이때 현재까지 수행되던 레지스터 상태 및 프로그램 카운터 값을 PCB에 저장한다. 

</br>

### 요구 페이징의 성능

요구 페이징 기법의 성능에 가장 큰 영향을 미치는 요소는 페이지 부재의 발생 빈도이다. page fault가 일어나면 요청된 페이지를 디스크로부터 메모리로 읽어오는 막대한 오버헤드가 발생하기 때문이다. 

**유효 접근시간 (effective access time)**

(1-P) X 메모리 접근 시간 +

P X ( 페이지 부재 발생 처리 오버헤드 + 메모리에 빈 프레임이 없는 경우 스왑아웃 오버헤드 + 요청된 페이지의 스왑 인 오버헤드 + 프로세스 재시작 오버헤드)

P: 페이지 부재 발생비율

</br>

## 페이지 교체 (page replacement)

교체 알고리즘의 목표는 페이지 부재율을 최소화하는 것이다 .

가까운 미래에 참조될 가능성이 가장 적은 페이지를 선택해서 내쫓는 것이 성능 향상


</br>

### 최적 페이지 교체

발레디의 최적 알고리즘 : 가장 먼 미래에 참조될 페이지를 쫓아낸다.

이 알고리즘은 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고 있다는 전제하에 알고리즘을 운영하므로 실제 시스템에서 온라인으로 사용할 수 있는 알고리즘은 아니다. 이러한 알고리즘을 오프라인 알고리즘이라고 한다.

발레디의 알고리즘은 어떤 경우보다도 가장 적은 페이지 부재율을 보장하므로 성능의 상한선(upper bound)를 제공한다. 

</br>

### 선입선출 알고리즘

페이지 교체 시 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 내쫓는다.

이 알고리즘에서는 물리적 메모리의 공간이 늘어났음에도 오히려 성능은 더 나빠질 수도 있다. 이러한 상황을 FIFO의 이상현상(FIFO anomaly)이라고 부른다.

</br>

### LRU 알고리즘 (Least Recently Used)

메모리 페이지의 참조 성향 중 중요한 한 가지 성질로 시간지역성 (temporal locality)이라는 것이 있다. 이 성질은 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질을 말한다. LRU 알고리즘은 이 성질을 활용하여 페이지 교체 시 가장 오래전에 참조가 이루어진 페이지를 쫓아낸다. 

</br>

### LFU 알고리즘 (Least Frequently Used)

물리적 메모리 내에 존재하는 페이지 중에서 과거에 참조 횟수가 가장 적었던 페이지를 쫓아내고 그 자리에 새로 참조될 페이지를 적재한다. 최저 참조 페이지가 여러개면 그 중에 임의로 하나를 선정애 쫓아낸다. 보통 그 중 오래된 것을 쫓아낸다. 

LFU 알고리즘은 페이지의 참조 횟수를 계산하는 방식에 따라 Incache-LFU와 Perfect-LFU로 나뉜다.

</br>

**Incache-LFU**

페이지가 물리적 메모리에 올라온 후부터 참조 횟수를 카운트 하는 방식

페이지가 메모리에서 쫓겨났다가 다시 들어온 경우 참조 횟수는 1부터 다시 시작.

</br>

**cache-LFU**

메모리에 올라와 있는지 상관없이 그 페이지의 과거 총 참조 횟수를 카운트하는 방식

이 방식은 페이지의 참조 횟수를 정확히 반영할 수 있다는 장점이 있지만, 메모리에서 쫓겨난 페이지의 참조 기록까지 모두 보관하고 있어야 하므로 오버헤드가 상대적으로 크다.

LFU는 LRU에 비해 오랜시간 동안의 참조 기록을 반영할 수 있다는 장점이 있다. 하지만 LFU는 시간에 따른 페이지 참조의 변화를 반영하지 못하고, LRU보다 구현이 복잡하다.

</br>

### 클럭 알고리즘

LRU와 LFU 알고리즘은 페이지의 참조 시각 및 참조 횟수를 소프트웨어적으로 유지하고 비교해야하므로 알고리즘의 운영에 시간적인 오버헤드가 발생한다.  

클럭 알고리즘은 하드웨어적인 지원을 통해 이와 같은 알고리즘의 운영 오버헤드를 줄인 방식이다. 

LRU 알고리즘이 가장 오래전에 참조된 페이지를 교체하는 것에 비해 클럭 알고리즘은 오랫동안 참조되지 않은 페이지 중 하나를 교체한다. 그래서 클럭 알고릐즘은 LRU를 근사 시킨 알고리즘으로 NUR(Not Used Recently)이나 NRU(Not Recently Used)로 불리기도 한다.

클럭 알고리즘은 교체할 페이지를 선정하기 위해 페이지 프레임들의 참조비트 (reference bit)를 순차적으로 조사한다. 참조비트는 각 프레임마다 하나씩 존재하며 그 프레임 내의 페이지가 참조될 때 하드웨어에 의해 1로 자동 세팅된다. 여기서 클럭 알고리즘은 참조비트가 1인 페이지는 0으로 바꾼 후 그냥 지나가고 참조비트가 0인 페이지는 교체하낟. 모든 페이지 프레임을 다 조사한 경우 첫 번째 페이지 프레임부터 조사 작업을 반복한다. 이 방식은 간단히 말해 시곗바늘이 한바퀴 도는 동안 다시 참조되지 않은 페이지를 교체하는 것이다. 

</br>

## 페이지 프레임 할당

### 균등할당(equal allocatoin)

모든 프로세스에게 페이지 프레임을 균일하게 할당

### 비례할당(proportional allocatoin)

프로세스의 크기에 비례해 페이지 프레임을 할당. 이 방식은 프로세스의 크기가 모두 균일하지 않다는 점에 착안한 방식으로, 프로세스의 크기를 고려한 균등할당 방식으로 볼 수 있다. 

### 우선순위 할당(priority allocation)

프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당. 이 방식은 프로세스 중 당장 CPU에서 실행될 프로세스와 그렇지 않은 프로세스를 구분하여 전자 쪽에 더 많은 페이지 프레임을 할당하는 방식

</br>

## 전역 교체와 지역 교체

교체 대상이 될 프레임의 범위를 어떻게 정할것인가

### 전역 교체

모든 페이지 프레임이 교체 대상이 될 수 있는 방법이다. 이 방법은 프로세스마다 메모리를 할당하는 것이 아닌 전체 메모리를 각 프로세스가 공유해서 사용하고 교체 알고리즘에 근거해서 할당하는 메모리 양이 가변적으로 변하는 방법이다. 

### 지역 교체

현재 수행 중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정할 수 있는 방법이다. 이 방법은 프로세스마다 페이지 프레임을 미리 할당하는 것을 전제로 한다. 

</br>

## 스레싱

집중적으로 참조되는 헤이지들의 집합을 메모리에 한꺼번에 적재하지 못하면 page fault rate (페이지 부재율)이 크게 상승해 CPU 이용률이 급격히 떨어질 수 있다. 이러한 현상을 thrashing(스레싱)이라고 한다. 

MPD(Multi-Programming Degree: MPD) : 다중 프로그래밍의 정도, 메모리에 동시에 올라간 프로세스의 수

CPU 이용률이 낮을 경우 MPD를 높인다. 그런데 MPD가 과도하게 높아지면 각 프로세스에 할당되는 메모리의 양이 지나치게 감소하게 된다. 페이지 부재가 발생하게 되면 디스크 I/O 작업을 수반하므로 문맥교환을 통해 다른 프로세스에게 CPU가 할당된다. 모든 프로세스가 페이지 부재를 발생시켜 시스템은 페이지 부재를 처리하느라 분주해지고 CPU이용률은 급격히 떨어진다. 이 상황을 운영체제는 메모리에 올라와 있는 프로세스 수가 적어 이러한 현상이 발생했다고 판단하고, MPD를 높이기 위해 또 다른 프로세스를 메모리에 추가하게 된다. 

할당된 프레임 수가 계속해서 감소하고 페이지 부재는 더욱 빈번히 발생하게 되면서 프로세서들은 서로의 페이지를 교체하며 스왑 인과 스왑 아웃을 지속적으로 발생시켜 CPU는 대부분의 시간에 일을 하지 않게되는데, 이런 상황을 스래싱이라고 한다. 

MDP를 적절히 조절해 CPU 이용률을 높이는 동시에 스레싱 발생을 방지하는 방법에는 워킹셋 알고리즘과 페이지 부재 빈도 알고리즘이 있다. 

</br>

### 워킹셋(working-set) 알고리즘

프로세스는 일정 시간 동안 특정 주소 영역을 집중적으로 참조하는 경향이 있다. 이렇게 집중적으로 참조되는 페이지들의 집합을 지역성 집합(locality set)이라고 한다. 워킹셋 알고리즘은 이러한 지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 알고리즘을 뜻한다. 

워킹셋 : 프로세스가 일정 시간동안 원활히 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 페이지들의 집합.

이 워킹셋이 모두 메모리에 올라갈 수 있는 경우에만 메모리 할당, 그렇지 않은 경우에는 그 프로세스의 주소 공간 전체를 디스크로 스왑아웃.

</br>

### 페이지 부재 빈도(page-fault frequency)

프로세스의 페이지 부재율을 주기적으로 조사하고 이 값에 근거해서 각 프로세스에 할당할 메모리 양을 동적으로 조절한다. 어떤 프로세스의 페이지 부재율이 시스템에서 미리 정해놓은 상한 값을 넘게 되면 이 프로세스에 할당된 프레임의 수가 부족하다고 판단하여 이 프로세스에게 프레임을 추가로 할당한다. 반면, 프로세스의 페이지 부재율이 하한값 이하로 떨어지면 이 프로세스에게 필요 이상으로 많은 프레임이 할당된 것으로 간주해 할당된 프레임의 수를 줄인다.
