# 7장. 메모리 관리

우리가 흔히 사용하는 컴퓨터 시스템은 32비트 혹은 64비트 주소 체계를 사용하고 있다. 32비트의 주소 체계를 사용할 경우 2³²가지의 서로 다른 메모리 위치를 구분할 수 있게 된다. 컴퓨터 상의 주소는 32비트를 그대로 사용하지 않고 효율적인 운영을 위해 연속된 일련의 영역을 행정구역처럼 묶어서 사용한다. 보통 4KB(=2¹²byte) 단위로 묶어서 페이지(page)라는 하나의 행정구역을 만든다. 즉, 32비트 주소 중 하위 12비트는 페이지 내에서 주소를 나타낸다. 

## 주소 바인딩

프로그램이 실행을 위해 메모리에 적재되면 그 프로세스를 위한 독자적인 주소 공간이 생성된다. 이 주소를 **논리적 주소**(logical address) 혹은 **가상 주소**(virtual address)라고 부른다. 

CPU는 이와 같이 프로세스마다 독립적으로 갖는 논리적 주소에 근거해 명령을 실행한다. **논리적 주소**는 각 프로세스마다 독립적으로 할당되며 0번지부터 시작된다. 반면 **물리적 주소**(physical address)는 물리적 메모리에 실제로 올라가는 위치를 말한다. 보통 물리적 메모리의 낮은 주소 영역에는 운영체제가 올라가고, 높은 주소 영역에는 사용자 프로세스들이 올라간다.

**주소 바인딩** : 

프로세스의 논리적 주소를 물리적 메모리 주소로 연결시켜주는 작업

프로세스가 실행되기 위해서는 해당 프로그램이 물리적 메모리에 올라가 있어야 한다. CPU가 기계어 명령을 수행하기 위해 논리적 주소를 통해 메모리 참조를 하게되면 해당 논리적 주소가 물리적 메모리의 어느 위치에 매핑되는지 확인한다.

</br>

### 주소 바인딩의 방식

프로그램이 적재되는 **물리적 메모리의 주소가 결정되는 시기**에 따라 세 가지로 분류 가능 

**컴파일 타임 바인딩(compile time binding)**

물리적 메모리 주소가 프로그램을 컴파일할 때 결정되는 주소 바인딩 방식

프로그램이 절대주소로 적재된다는 뜻에서 절대토드(absolute code)를 생성하는 바인딩 방식이라고도 부른다. 

이와 같은 바인딩 방식에서 프로그램이 올라가 있는 물리적 메모리의 위치를 변경하고 싶다면 컴파일을 다시 하는 수고가 필요하다.

→ 비현실적이고 현대의 시분할 컴퓨팅 환경에서는 잘 사용하지 않음

**로드 타임 바인딩 (load time binding)**

프로그램의 실행이 시작될 때에 물리적 메모리 주소가 결정되는 주소 바인딩 방식

이 방식에서는 로더(loader, 사용자 프로그램을 메모리에 적재시키는 프로그램)의 책임하에 물리적 메모리 주소가 부여되며 프로그램이 종료될 때가지 물리적 메모리상의 위치가 고정된다. 이 방식은 컴파일러가 재배치 가능 코드(relocatable code)를 생성한 경우에 가능한 주소 바인딩 장식이다. 

**실행시간 바인딩(execution time binding or run time binding)**

프로그램이 실행을 시작한 후에도 그 프로그램이 위치한 물리적 메모리상의 주소가 변경될 수 있는 바인딩 방식. 

이 방식에서는 CPU가 주소를 참조할 때마다 해당 데이터가 물리적 메모리의 어느 위치에 존재하는지, 주소 매핑 테이블을 이용해 바인딩을 점검해야 한다. 또한 다른 방식들과 달리 base register 와 limit register를 포함해 MMU(Memory Management Unit, 논리적 주소를 물리적 주소로 매핑해주는 하드웨어 장치),라는 하드웨어적인 지원이 뒷받침 되어야 한다. 

</br>

### MMU 기법

CPU가 특정프로세스의 논리적 주소를 참조하려고 할 때 MMU 기법은 그 주소값에 기준 레지스터의 값을 더해 물리적 주소값을 얻어낸다.

기준 레지스터는 재배치 레지스터(relocation register)라고도 부르며 그 프로세스의 물리적 메모리 시작 주소를 갖고 있다. MMU 기법에서는 프로그램의 주소 공간이 물리적 메모리의 한 장소에 연속적으로 적재되는 것으로 가정한다. 

프로세스는 자기 자신만의 고유한 주소 공간을 가지고 있으므로 동일한 주소값이라 하더라도 각 프로세스마다 서로 다른 내용을 담고 있게 된다.  MMU 기법에서는 문맥교환으로 CPU에서 수행 중인 프로세스가 바뀔 때마다 재배치 레지스터의 값을 그 프로세스에 해당하는 값으로 재설정함으로써 위치에 접근하는 것을 지원한다. 

**고려해야 할 사항** 

흔히 사용하는 다중 프로그래밍 환경에서 물리적 메모리 안에는 여러 개의 프로세스가 동시에 올라가 있는 경우가 대부분이다. MMU 방식을 사용하는 경우 주소 변환을 하는 경우 값을 더한 결과가 해당 프로세스의 주소 공간을 벗어하는 경우가 발생할 수 있다. 이렇게 되면 메모리 보안이 이루어 지지 않아 치명적인 상황이 발생할 수 있다. 운영체제는 이러한 특수 상황이 발생하는 것을 방지하기 위해 **한계 레지스터 (limit register)** 라는 또 하나의 레지스터를 사용한다. 

한계 레지스터는 프로세스가 자신의 주소 공간을 넘어서는 메모리 참조를 하려고 하는지 체크하는 용도로 사용되며, 현재 CPU에서 수행중이 프로세스의 노리적 주소의 최댓값, 즉 그 프로세스의 크기를 담고 있다. 

</br>

## 메모리와 관리와 관련된 용어

### 동적로딩 (dynamic loading)

여러 프로그램이 동시에 메모리에 올라가서 수행되는 다중 프로그래밍 환경에서 메모리 사용의 효율성을 높이기 위해 사용하는 기법 중 하나이다. 프로세스 내에서 실행에 필요한 부분이 실제로 불릴 때마다 메모리에 적재하는 것을 말한다. 

동적 로딩 기법은 사용되지도 않을 많은 양의 코드가 메모리에 올라가는 것을 막아 메모리를 좀 더 효율적으로 사용할 수 있도록 한다. 

동적 로딩은 운영체제의 특별한 지원없이 프로그램 자체에서 구현이 가능하며 운영체제가 라이브러리를 통해 지원할 수도 있겠다. 

</br>

### 동적 연결 (dynamic linking)

연결(linking): 프로그래머가 작성한 소스 코드를 컴파일하여 생성된 목적 파일(object file)과, 이미 컴파일된 라이브러리 파일들을 묶어 하나의 실행파일을 생성하는 과정을 말한다. 

동적 연결은 컴파일을 통해 생성된 목적 파일과 라이브러리 파일 사이의 연결을 프로그램의 실행 시점까지 지연시키는 기법이다. 

이와 대비되는 정적 연결(static linking)에서는 프로그래머가 작성한 코드와 라이브러리 코드가 모두 합쳐져서 실행파일이 생성된다. 따라서 실행파일의 크기가 상대적으로 크며, 동일한 라이브러리를 각 프로세스가 개별적으로 메모리에 적재해야 하므로 물리적 메모리가 낭비되는 단점이 있다. 

동적연결을 가능하게 하기 위해 실행파일의 라이브러리 호출 부부넹 해당 라이브러리의 위치를 찾기 위한 스텁(stub)이라는 작은 코드를 둔다. 라이브러리 호출 시 스텁을 통해 해당 라이브러리가 메모리에 이미 존재하는지 살펴보고 그럴 경우 그 주소의 메모리 위치에서 직접 참조하며, 그렇지 않을 경우 디스크에서 동적 라이브러리 파일을 찾아 메모리로 적재한 후 수행하게 된다. 

즉, 동적연결에서는 다수의 프로그램이 공통으로 사용하는 라이브러리를 메모리에 한 번만 적재하므로 메모리 사용의 효율성을 높일 수 있다. 이런 동적연결 기법은 운영체제의 지원을 필요로 한다. 

</br>

### 중첩(overlays)

프로세스의 주소 공간을 분할해 실제 필요한 부분만을 메모리에 적재하는 기법을 말한다. 

동적로딩과 개념적으로 유사하지만, 사용하는 이유는 상이하다. 

중첩은 초창기의 컴퓨터 시스템에서 물리적 메모리의 크기 제약으로 인해 하나의 프로세스조차도 메모리에 한꺼번에 올릴 수 없을 때, 프로세스의 주소 공간을 분할해서 당장 필요한 일부분을 메모리에 실행하는 기법을 뜻한다. 

즉, 동적로딩은 메모리에 더 많은 프로세스를 동시에 올려놓고 실행하기 위한 용도인 반면, 중첩은 단일 프로세스만을 메모리에 올려놓은 환경에서 메모리 용량보다 큰 프로세스를 실행하기 위한 어쩔 수 없는 선택이었다. 

중첩은 운영체제의 지원없이 프로그래머에 의해 구현되어야 했다.

</br>

### 스와핑(swapping)

메모리에 올라온 프로세스의 주소 공간 전체를 디스크의 스왑 영역에 일시적으로 내려놓는 것을 말한다. 이때 스왑 영역은 backing store라고도 부르며, 디스크 내에 파일 시스템과는 별도로 존재하는 일정 역역을 말한다. 

스왑영역은 다수의 사용자 프로세스를 담을 수 있을 만큼 충분히 큰 저장공간이어야 하고 어느 정도의 접근 속도가 보장되어야 한다. 

**스와핑이 일어나는 과정**

일반적으로 스와핑은 스와퍼(swapper)라고 불리는 중기 스케줄러에 의해 스왑 아웃 시킬 프로세스를 선정한다. 스와핑의 가장 중요한 역할은 메모리에 존재하는 프로세스의 수를 조절하는 것이다. 너무 많은 프로그램이 메모리에 동시에 올라오게 되면 프로세스당 할당되는 메모리의 양이 지나치게 적어져 시스템 전체의 성능이 크게 떨어진다. 스와핑은 이러한 문제를 해결하기 위해 현재 남아있는 프로그램에게 적절한 메모리 공간을 보장한다. 

스와핑에서는 보통 디스크 내의 스왑 영역에 프로세스의 주소 공간이 순차적으로 저장되기 때문에, 스와핑에 소요되는 시간은 디스크의 탐색 시간이나 회전 지연 시간보다는 디스크 섹터에서 실제 데이터를 읽고 쓰는 전송시가닝 대부분을 차지한다. 

</br>

## 물리적 메모리의 할당 방식

물리적 메모리는 운영체제 상주 영역과 사용자 프로세스 영역으로 나뉘어 사용된다. 운영체제 상주 영역은 인터럽트 벡터와 함께 물리적 메모리의 낮은 주소 영역을 사용하며, 운영체제 커널이 이곳에 위치하게 된다. 사용자 프로세스 영역은 물리적 메모리의 높은 주소 영역을 사용하며 여러 사용자 프로세스들이 이곳에 적재되어 실행된다. 

**사용자 프로세스 영역의 관리 방법**

연속할당 방식 - 고정분할 방식, 가변 분할 방식

불연속할당 방식 - 페이징 기법, 세그멘테이션 기법, 페이지드 세그먼테이션 기법

</br>

### 연속할당 방식 (contiquous allocation)

프로세스를 메모리에 올릴 때 그 주소 공가능ㄹ 여러 개로 분할하지 않고 물리적 메모리의 한 곳에 연속적으로 적재하는 방식

</br>

**고정분할 방식(fixed partition allocation)**

물리적 메모리를 주어진 개수만큼의 영구적인 분할로 미리 나누어두고 각 분할에 하나의 프로세스를 적재해 실행시킬 수 있게 한다. 따라서 고정분할 방식은 동시에 메모리에 올릴 수 있는 프로그램의 수가 고정되어 있으며 수행 가능한 프로그램의 최대 크기 또한 제한된다는 점에서 가변분할 방식에 비해 융통성이 떨어진다.

외부조각(external fragmentation)과 내부조각(internal fragmentation)이 발생할 수 있다.

외부조걱 : 프로그램의 크기보다 분할의 크기가 작은 경우 분할이 비어있음에도 불구하고 프로그램을 적재하지 못하기 때문에 발생하는 메모리 공간

내부 조각 : 프로그램의 크기보다 분할의 크기가 큰 경우 해당 분할에 프로그램을 적재하고 남는 메모리 공간 → 공간을 활용할 수 없어 메모리 낭비 (공간 하나당 프로그램 하나)

</br>

**가변분할 방식(variable partition allocation)**

메모리에 적재되는 프로그램의 크기에 따라 분할의 크기, 개수가 동적으로 변하는 방식.

내부조각은 발생하지 않지만, 이미 메모리에 존재하는 프로그램이 종료될 경우 중간에 빈 공간이 발생하게 되며, 이 공간이 외부 조각이 될 가능성이 있다.

외부 조각을 해결하기 위한 방법 : **컴팩션(compaction)**

물리적 메모리 중에서 프로세스에 의해 사용중인 메모리 영역을 한쪽으로 몰고 가용 공간들을 다른 한쪽으로 모아 하나의 큰 가용 공간을 만드는 방법. 현재 수행중인 프로세스의 메모리 상의 위치를 상당 부분을 이동 시켜 비용이 매우 많이 드는 작업이다.또한, 실행시간 바인딩 방식이 지원되는 환경에서만 수행 가능하다. 

</br>

**동적메모리 할당 문제**

가변 분할 방식에서 주요하게 다루는 쟁점 중 하나. 주소 공간의 크기가 n인 프로세스를 메모리에 올릴 때 물리적 메모리 내 가용 공간 중 어떤 위치에 올릴 것인지 결정하는 문제.

해결방법 1. 최초 적합 (first fit) : 크기가 n 이상인 가용 공간 중 가장 먼저 찾아지는 곳에 프로세스 할당. 가용공간을 모두 탐색하는방법이 아니므로 시간적인 측면에서 효율적

해결방법 2. 최적적합(best fit) : 크기가 n 이상인 가장 작은 가용 공간을 찾아 그곳에 새로운 프로그램을 할당. 가용공간이 크기순으로 정렬되어 있지 않은 경우 모든 가용 공간을 탐색해야하므로 시간적 오버헤드가 발생하고 다수의 매우 작은 가용공간들이 생성될 수 있다는 단점이 있지만, 공간적인 측면에서는 효율적.

해결방법 3. 최악적합(worst fit): 가용 공간 중에서 가장 크기가 큰 곳에 새로운 프로그램을 할당. 모든 가용 공간을 탐색해야하는 오버헤드. 

→ 실제 시스템에서는 최초적합과 최적적합 방식이 최악 적합 장식에 비해 속도와 공간 이용률 측면에서 효과적임

</br>

### 불연속할당 방식(noncontinguous allocation)

하나의 프로세스가 물리적 메모리의 여러 위치에 분산되어 올라갈 수 있는 메모리 할당 기법

**페이징 (paging)** : 하나의 프로그램을 분할하는 기준에 따라 동일한 크기로 나누어 메모리에 올리는 기법

**세그먼테이션 (segmentation)** : 크기는 일정하지 않지만 의미 단위로 나누어 메모리에 올리는 기법

**페이지드 세그먼테이션 (paged sementtation)** : 세그먼테이션을 기본으로 하되 이를 다시 동일 크기의 페이지로 나누어 메모리에 올리는 기법

</br>

## 페이징 기법

프로세스의 주소 공간을 동일한 크기의 페이지 단위로 나누어 물리적 메모리의 서로 다른 위치에 페이지들을 저장하는 방식. 

페이징 기법에서는 물리적 메모리를 페이지와 동일한 크기의 프레임(frame)으로 미리 나누어 둔다. 빈 프레임이 있으면 어느 위치든 사용 가능하므로 연속 할당에서 발생했던 동적 메모리 할당 문제가 발생하지 않는다. 외부 조각 문제는 발생하지 않지만, 프로세스의 주소 공간 중 제일 마지막 페이지는 내부 조각이 발생할 가능성이 있다.

페이징 기법에서는 주소 변환 절차가 다소 복잡하다. 논리적 주소를 물리적 주소로 변환하는 작업이 페이지 단위로 이루어져야 하기 때문이다. 페이지별 주소 변환 정보를 유지하고 있어야 한다. 따라서 모든 프로세스가 각각의 주소 변환을 위한 페이지 테이블(page table)을 가지며, 이 테이블은 프로세스가 가질 수 있는 페이지의 개수만큼 주소 변환 엔트리를 가지고 있는다. 

</br>

### 주소 변환 기법

페이징 기법에서는 CPU가 사용하는 논리적 주소를 **페이지 번호(p)**와 **페이지 오프셋(d)**으로 나누어 주소 변환에 사용한다. 

페이지 번호는 각 페이지별 주소 변환 정보를 담고 있는 페이지 테이블 접근 시 인덱스로 사용되고, 해당 인덱스의 항목에는 그 페이지의 물리적 메모리 상의 기준 주소(시작 위치)가 저장된다. 

페이지 오프셋은 하나의 페이지 내에서의 변위를 알려준다. 즉, 논리적 주소에 대응하는 물리적 주소를 얻을 수 있다.

</br>

### 페이지 테이블의 구현

페이지 테이블은 페이징 기법에서 주소 변환을 하기 위한 자료구조로, 물리적 메모리에 위치하게 된다. 

현재 CPU에서 실행중인 프로세스의 페이지 테이블에 접근하기 위해 운영체제는 2개의 레지스터를 사용한다. 페이지 테이블 기준 레지스터 (page-table base register), 페이지 테이블 길이 레지스터(page-table length register)

메모리에 한번 접근하기 위해서는 매번 메모리에 두번 접근(주소변환을 위한 페이지 테이블 접근, 변환된 주소에서 실제 데이터 접근)을 하는 오버레드가 뒤따른다. 이러한 오버헤드를 줄이고 메모리의 접근 속도를 향상시키기 위해 TLB(Translation Look-aside Buffer)라고 불리는 고속의 주소 변환용 하드웨어 캐시가 사용되기도 한다.

**TLB에 의한 페이징 기법의 주소 변환**

TLB를 사용한 주소 변환의 경우에는 프로세스의 모든 페이지에 대한 주소 변환 정보를 TLB가 가지고 있지 않기 때문에 페이지 번호와 이에 대응하는 프레임 번호가 쌍으로 저장되어야 한다. 

또한 TLB를 통한 주소 변환을 위해서는 TLB의 모든 항목을 다 찾아봐야 하는 오버헤드가 발생한다. (주소변환 정보가 TLB에 있는지 확인하기 위해서). 이러한 오버헤드를 줄이기 위해 보통 병렬 탐색이 가능한 연관 레지스터 (associative register)를 사용한다. 

**연관 레지스터를 사용할 때 평균적인 메모리 접근 시간 : EAT(Effective Access Time)**

EAT = (1+ɛ)ɑ + (2+ɛ)(1-ɑ) = 2 + ɛ - ɑ

ɑ : 요청된 페이지에 대한 주소 변환 정보가 연관 레지스터에 존재할 확률

ɛ: 연관 레지스터에 접근하는 시간

1: 메모리에 접근하는 시간

없는 경우에는 페이지 테이블 접근 시간 + 실제 원하는 데이터에 접근하는 시간 = 2

</br>

### 계층적 페이징

현대 컴퓨터는 주소 공간이 매우 큰 프로그램을 지원한다. 수행중인 프로세스가 증가함에 따라 전체 메모리의 상당 부분이 주소 변환을 위한 페이지 테이블에 할애되어 실제로 사용 가능한 메모리 공간이 크게 줄어들게 된다.  따라서 페이지 테이블에 사용되는 메모리 공간의 낭비를 줄이기 위해 **2단계 페이징 기법**을 사용한다.

**2단계 페이징 기법**

2단계 페이징 기법에서는 주소 변환을 위해 외부 페이지 테이블과 내부 페이지 테이블의 두 단계에 걸친 페이지 테이블을 사용한다. 사용되지 않는 주소 공간에 대해서는 외부 페이지 테이블의 항목을 NULL로 설정하며, 여기에 대응하는 내부 페이지 테이블을 생성하지 않는 것이다. 

이 기법은 공간적인 이득은 볼 수 있지만, 주소 변환을 위해 접근해야하는 페이지 테이블의 수가 증가하므로 시간적인 손해가 뒤따르게 된다.

이 기법에서는 프로세스의 논리적 주소를 두 종류의 페이지 번호(P1, P2)와 페이지 오프셋(d)로 구분한다. P1은 외부 페이지 테이블의 인덱스이고, P2는 내부 페이지 테이블의 인덱스이다. 

(계산하는 과정 생략, 나중에 다시 공부하자)

프로세스의 주소 공간이 커질수록 페이지 테이블의 크기도 커지므로 주소 변환을 위한 메모리 공간 낭비 역시 더 심각해지게 된다. 2단계를 넘어 3 4단계에 이르는 다단계 페이지 테이블이 필요하게 된다. 이는 공간의 소모는 줄일 수 있지만, 그만큼 메모리 접근 횟수가 많아지기 때문에 메모리 접근 시간이 늘어나는 문제가 발생할 수 있다. 이런 오버헤드를 줄이기 위해서는 TLB를 사용하는 것이 효과적이다. → 다단계 테이블 + TLB

</br>

### 역페이지 테이블

논리적 주소에 대해 페이지 테이블을 만드는 것이 아니라 물리적 주소에 대해 페이지 테이블을 만드는 방식이다. 즉, 프로세스마다 페이지 테이블을 두지 않고, 시스템 전체에 페이지 테이블을 하나만 두는 방법이다. 

페이지 테이블의 각 항목은 어느 프로세스의 어느 페이지가 이 프레임에 저장되었는지의 정보를 보관하고 있다. 즉 페이지 테이블의 각 항목은 프로세스 번호 (pid)와 그 프로세스 내의 논리 페이지 번호(P)를 담고 있게 된다. 

역페이지 테이블에서의 주소 변환은 다소 비효율적인 측면이 있다. 역페이지 테이블에 주소 변환요청이 들어오면, 그 주소를 담은 페이지가 물리적 메모리에 존재하는지 여부를 판단하기 위해 페이지 테이 전체를 다 탐색해야하는 어려움이 있다. 이는 상당한 시간을 필요로 하기 때문에 일반적으로 역페이지 테이블은 메모리에 유지하는 대신 연관 레지스터에 보관하여 시간적 효율성을 꾀한다.

</br>

### 공유 페이지

**공유 코드**(shared code): 메모리 공간의 효율적인 사용을 위해 여러 프로세스에 의해 공통으로 사용될 수 있도록 작성된 코드. 재진입 가능 코드(re-entrant code), 순수 코드(pure code)라고도 불리며 읽기 전용이다.

**공유 페이지**(shared page): 공유 코드를 담고 있는 페이지. 물리적 메모리에 하나만 적재되어 메모리를 더 효율적으로 사용하게한다. 공유 페이지는 그 페이지를 공유하는 모든 프로세스의 주소 공간에서 동일한 페이지 번호를 가져야 한다. 

</br>

### 메모리 보호

페이지 테이블의 각 항목에는  주소 변환 정보뿐 아니라 메모리 보호를 위한 보호비트(protextion bit)와 유효-무효 비트(valid-invalid bit)를 두고 있다.

보호비트 : 각 페이지에 대한 접근 권한의 내용을 담고 있다. 각 페이지에 대해 어떠한 접근을 허용하는지의 정보가 보호비트에 저장된다. 즉 보호비트는 각 페이지에 대해 읽기-쓰기 전용 등의 접근 권한을 설정하는데에 사용된다.

유효-무효 비트: 해당 페이지의 내용이 유효한지. 유효하면 해당 메모리 프레임에 그 페이지가 존재함을 뜻하며, 접근이 허용된다. 무효하면 프로세스가 그 주소 부분을 사용하지 않거나, 해당 페이지가 물리적 메모리에 올라와 있지 않고 백킹스토어에 존재해 해당 메모리 프레임에 유효한 접근 권한이 없다는 의미를 지닌다.

</br>

## 세그먼테이션

하나의 프로세스를 구성하는 주소 공간은 일반적으로 코드, 데이터, 스택 등의 의미있는 단위들로 구성된다. 세그먼트는 이와 같이 주소 공간을 기능 단위 또는 의미 단위로 나눈 것을 뜻한다. 

세그먼트는 논리적인 단위로 나눈 것이기 때문에 크기가 균일하지 않다. 크기가 균일하지 않은 채 메모리에 적재해 부가적인 관리 오버헤드가 뒤따르게 된다. 

또한 외부 조각이 생기며, 세그먼트를 어느 가용공간에 할당할 것인지 결정하는 문제가 발생한다. 

세그먼테이션 기법에서는 논리적 주소가 <세그먼트 번호, 오프셋>으로 나뉘어 사용된다.

세그먼트 번호 : 해당 논리적 주소가 프로세스 주소 공간 내에서 몇 번째 세그 먼트에 속하는지

오프셋 : 그 세그먼트 내에서 얼마만큼 떨어져 있는지

</br>

**세그먼트 테이블**

이 기법에서는 주소 변환을 위해 세그먼트 테이블을 사용하는데, 각 항목은 기준점(base)와 한계점(limit)을 가지고 있다. 기준점은 물리적 메모리에서 그 세그먼트의 시작 위치를 내타내고, 한계점은 그 세그먼트의 길이를 말한다.

주소 변환시 세그먼트 테이블 기준 레지스터(STBR)와 세그먼트 테이블 길이 레지스터(STLR)를 사용한다. STBR는 현재 CPU에서 실행중인 프로세스의 세그먼트 테이블이 메모리의 어느 위치에 있는지 그 시작 주소를 담고 있으며, STLR은 그 프로세스의 주소 공간이 총 몇 개의 세그먼트로 구성되는지, 즉 세그먼트의 개수를 나타낸다.

세그먼테이션 기법에서는 논리적 주소를 물리적 주소로 변환하기 전에 두가지 사항을 확인한다. 

1. 요청된 세그먼트 번호가 STLR에 저장된 값보다 작은 값인가?
2. 논리적 주소의 오프셋값이 그 세그먼트의 길이보다 작은 값인가?


페이징 기법과 마찬가지로 세그먼테이션 기법에서도 세그먼트 테이블의 각 항목에 보호비트와 유효 비트를 둔다. 보호비트는 각 세그먼트에 대해 읽기/쓰기/실행 등의 권한이 있는지를 나타내며, 유효비트는 각 세그먼트의 주소 변환 정보가 유효한지, 즉 해당 세그먼트가 현재 물리적 메모리에 적재되어 있는지를 나타낸다. 

세그먼트는 의미 단위로 나누어져 있기 때문에 공유와 보안의 측면에서 페이징 기법에 비해 훨씬 효과적이다. 공유하려는 코드와 사유 데이터 영역이 동일 페이지에 공존하는 경우가 페이징 기법에서 나타날 수 있는데, 이는 세그먼테이션 기법에서 나타나지 않는다. 

</br>

## 페이지드 세그먼테이션

페이징 기법과 세그먼테이션 기법의 장점만을 취하는 주소 변환기법이다.

프로그램을 의미있는 단위의 세그먼트로 나눈다. 단, 세그먼트는 동일한 크기 페이지들의 집합으로 구선된다. 그리고 물리적 메모리에 적재한느 단위는 페이지 단위이다. 

이 기법에서는 주소 변환을 위해 외부의 세그먼트 테이블과 내부의 세그먼트 테이블, 이렇게 두 단계의 테이블을 이용한다. 하나의 세그먼트가 여러 개의 페이지로 구성되므로 각 세그먼트마다 페이지 테이블을 갖게 된다. 

**<세그먼트 번호, 오프셋>으로 구성된 논리적 주소를 물리적으로 변환하는 과정**

논리적 주소의 상위 비트인 세그먼트 번호를 통해 세그먼트 테이블의 해당 항목에 접근한다. 

이 세그먼트 항목에는 세그먼트 길이와 그 세그먼트의 페이지 테이블 시작 주소가 들어 있다. 

세그먼트 길이값과 오프셋값을 비교한다.

문제가 없으면 오프셋값을 상위 하위 비트로 나누어 상위 비트는 그 세그먼트 내에서의 페이지 번호로 이용하고, 하위 비트는 페이지 내에서의 변위로 사용하게 된다.
